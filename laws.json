[
  {
    "Bill": "Status",
    "AB 2013": "Passed",
    "SB 813": "Not yet passed; reconsideration in 2026",
    "SB 579": "Not yet passed; pending committee approval",
    "SB 524": "Pending as of July 11, 2025",
    "SB 503": "In progress; pending",
    "SB 853": "In progress",
    "SB 420": "In progress",
    "SB 833": "Engrossed on June 3, 2025; currently pending in Assembly Privacy and Consumer Protection Committee with amendments; hearing scheduled for July 16, 2025.",
    "SB 489": "Engrossed on May 27, 2025; pending in Assembly Housing and Community Development Committee; hearing scheduled for July 16, 2025.",
    "SB 11": "Engrossed on June 2, 2025. Amended and re-referred to the Assembly Privacy and Consumer Protection Committee on July 10, 2025. Next Hearing: July 16, 2025, in State Capitol, Room 444.",
    "SB 468": "Introduced on February 19, 2025; held in committee and under submission as of May 23, 2025. Currently pending in the Senate Appropriations Committee.",
    "AB 979": "Engrossed on June 2, 2025 Passed Senate Privacy Committee on July 1, 2025 (13–0) Now pending in Senate Appropriations Committee (referred July 2, 2025)",
    "SB 243": "Engrossed on June 3, 2025 Advanced from Assembly Privacy Committee on July 8, 2025 (11–1 vote) Pending in Assembly Judiciary Committee (Hearing scheduled July 15, 2025)",
    "SB 384": "Engrossed on June 3, 2025 – 50% progression; Pending in Assembly Privacy and Consumer Protection Committee; Next Hearing: July 16, 2025 — State Capitol, Room 444; Vote from last committee: Passed 9–2 on July 1",
    "SB 53": "Engrossed in the California Senate as of May 28, 2025; Referred to Assembly Privacy and Consumer Protection Committee; Hearing scheduled: July 16, 2025 — State Capitol, Room 444"
  },
  {
    "Bill": "Effective",
    "AB 2013": "Effective January 1, 2026. Applies retroactively to generative models trained from 2022 onward",
    "SB 813": "On or after Janurary 1st, 2026",
    "SB 579": "N/A",
    "SB 524": "On or after Janurary 1st, 2026",
    "SB 503": "On or after Janurary 1st, 2026",
    "SB 853": "On or after Janurary 1st, 2026",
    "SB 420": "On or after Janurary 1st, 2026",
    "SB 833": "Takes effect upon passage, with implementation deadlines including: Annual assessments by state agency operators, Real-time oversight mechanisms in place before or during deployment, Event reporting deadlines vary by severity (4 hours to 14 days)",
    "SB 489": "On or after Janurary 1st, 2026",
    "SB 11": "If passed in 2025, it would likely take effect January 1, 2026, with some components (e.g. Judicial Council review) due by 2027.",
    "SB 468": "On or after Janurary 1st, 2026",
    "AB 979": "If passed in 2025, the California AI Cybersecurity Collaboration Playbook must be developed by July 1, 2026.",
    "SB 243": "If passed, provisions would take effect January 1, 2026, as per standard California legislative timelines unless otherwise specified.",
    "SB 384": "January 1, 2026, unless otherwise specified (typical for California laws passed during the 2025 session)",
    "SB 53": "Pending final passage. Will take effect January 1, 2026, unless otherwise specified for certain provisions."
  },
  {
    "Bill": "Summary",
    "AB 2013": "AB 2013 is a new California law going into effect January 1, 2026, requiring developers of generative AI models to disclose detailed information about the training data used to build their systems. This includes the source, type, collection date, and whether any biased, sensitive, or copyrighted material was used. The goal is to tackle the “black box” problem in AI by increasing transparency, making it easier to understand, audit, and regulate how AI systems are trained — especially regarding bias, misinformation (like deepfakes), and IP violations.",
    "SB 813": "SB 813 establishes Multistakeholder Regulatory Organizations (MROs)—private entities certified by the California Attorney General to set and enforce best-practice safety standards for high-risk AI models and applications. Certified developers may receive legal protections (e.g. a rebuttable presumption of due care in lawsuits), and MROs are tasked with auditing, certifying, reporting, and decertifying AI systems.",
    "SB 579": "SB 579 establishes a Mental Health and Artificial Intelligence Working Group under the California Government Operations Agency. The group’s mission is to: Evaluate AI's role in mental health diagnosis, treatment, and monitoring, identify risks like privacy violations, over-reliance, and use of AI chatbots, gather public and stakeholder input, deliver two reports to the Legislature: one in 2028, a follow-up in 2030. The bill emphasizes ethics, innovation, and practical training frameworks for mental health professionals. It sunsets in 2031.",
    "SB 524": "SB 524 requires all California law enforcement agencies using AI-generated content in official police reports to: Include disclosure language on every page of the report, Require a human signature verifying the report’s truthfulness, Retain first drafts generated by AI for as long as final versions, Prohibit AI-generated drafts from being used as official statements, Maintain an audit trail showing who used or modified the report and which media (audio/video) were used. This ensures transparency, accountability, and traceability in the use of AI for public safety documentation.",
    "SB 503": "SB 503 expands AI oversight in healthcare by requiring both developers and users (deployers) of AI systems in clinical decision-making or resource allocation to: Identify AI systems that have a known or reasonably foreseeable risk of biased impacts based on protected characteristics (like race, gender, etc.), Make reasonable efforts to mitigate bias in those systems, Continuously monitor and take proportionate steps to address any emerging bias over time. This includes AI used by hospitals, clinics, group practices, and solo physicians. It defines core terms like “developer,” “deployer,” and “biased impact,” and clarifies that compliance with the bill does not exempt entities from existing anti-discrimination laws.",
    "SB 853": "AB 853 expands California's AI transparency and provenance law to: Require large online platforms (2M+ monthly users) to retain and disclose provenance data (metadata about content origin and authenticity) for any content involving GenAI, Require capture device manufacturers (e.g., phone or camera makers) to include settings for users to embed provenance data (e.g., time, device info, latent disclosures), Ban GenAI hosting platforms from offering systems that don’t embed hard-to-remove disclosures into synthetic content, Prohibit software whose primary function is to remove those disclosures, and Impose civil penalties for noncompliance: $5,000 per violation/day, plus attorney’s fees.",
    "SB 420": "SB 420 — the California AI Accountability and Transparency Act — would impose strict requirements on developers and deployers of high-risk automated decision systems (ADS), especially those used in critical life areas (e.g., housing, employment, health care, education, lending, etc.). Key features include: Mandatory impact assessments before deployment or substantial modification, Required user disclosures, redress/appeals mechanisms, and human review options, Prohibition on state contracts with violators of civil rights laws. Enforcement by the Attorney General or Civil Rights Department, with civil penalties up to $25,000 per violation for algorithmic discrimination. The bill outlines a clear framework for governance, bias audits, transparency, and redress—inspired by principles in the EU AI Act and the NIST AI Risk Framework.",
    "SB 833": "SB 833 creates mandatory oversight and reporting rules for AI used in critical infrastructure by California state agencies and relevant private entities. It establishes: Human oversight requirements, Annual AI system assessments, Adverse event reporting mandates, Civil penalties for noncompliance, Strict disclosure limits on sensitive data",
    "SB 489": "AB 489 prohibits artificial intelligence (AI) and generative AI (GenAI) systems from using terms, letters, or phrases that falsely indicate or imply possession of a licensed health care profession in their advertising or functionality. This includes any AI-generated care, advice, reports, or assessments that suggest they come from a licensed health care professional when they do not. The bill extends the scope of existing laws that prohibit unlicensed use of health care professional titles to cover developers and deployers of AI/GenAI systems. Violations are subject to enforcement by the relevant health care professional licensing boards, with each misuse counted as a separate violation.",
    "SB 11": "SB 11 creates a broad legal and consumer protection framework around artificial intelligence technologies that can generate digital replicas of individuals, including their likeness or voice. It introduces five key regulatory and legal shifts: Expands criminal law to include digital impersonation (e.g., using deepfakes to falsely represent someone else) under existing false impersonation statutes. Amends Civil Code §3344 to: Recognize digital replicas as protected likenesses or voices, Remove the \"employee publication\" exemption, tightening commercial liability, Creates a new duty for AI providers to warn consumers (via an official DCA-drafted notice) about legal risks tied to misusing digital replica tools, Directs the Judicial Council to review and develop rules of court by Jan 1, 2027, on the admissibility of AI-generated/manipulated evidence, Enables civil penalties up to $25,000 per day for failing to display warnings when offering digital replica tools to consumers.",
    "SB 468": "SB 468 establishes a legal duty for businesses (termed \"covered deployers\") that deploy high-risk AI systems processing personal information to develop, implement, and maintain a comprehensive information security program. These programs must include administrative, technical, and physical safeguards proportionate to the business’s size, resources, and data volume. The bill details strict requirements including risk assessments, access controls, encryption, training, employee oversight, and breach response protocols. Violations are considered deceptive trade practices under California’s Unfair Competition Law. The California Privacy Protection Agency is authorized to adopt regulations, including setting fees (exempt from the APA for fees only).",
    "AB 979": "AB 979 mandates that the California Cybersecurity Integration Center (Cal-CSIC) create a statewide cybersecurity playbook specifically tailored to artificial intelligence systems. Its purpose is to improve information sharing, especially regarding threats and vulnerabilities from vendors, contractors, and others developing or operating AI tools in California. Key requirements: The “California AI Cybersecurity Collaboration Playbook” must: Be developed in consultation with the Office of Information Security and Government Operations Agency; Be informed by federal frameworks, especially the JCDC AI Cybersecurity Collaboration Playbook (2025); Include mandatory reporting mechanisms for state vendors/contractors using AI to report threats/vulnerabilities; Provide voluntary channels for others in the AI community to share cyber threat intelligence. Confidentiality protections: Any AI-related cybersecurity data shared under this framework is exempt from disclosure under California Public Records Act and may only be shared with authorized personnel.The bill contains legislative findings justifying limitations on public access to sensitive cybersecurity information, in compliance with the California Constitution.",
    "SB 243": "SB 243 establishes behavioral, safety, and transparency requirements for developers and providers of “companion chatbot platforms”—AI systems designed to simulate human interaction for social or emotional support. The bill is a first-of-its-kind AI mental health safeguarding law, aimed at reducing addiction-like engagement, protecting vulnerable users, and creating accountability for chatbot providers. Key provisions include: Ban on addictive mechanics: Companion chatbots must not provide rewards at unpredictable intervals (e.g., dopamine-triggering reinforcement schedules) or encourage excessive usage or engagement. Clear identification: Users must be notified at the start of each session—and every 3 hours thereafter—that they are speaking to an AI, not a human. Suicidal ideation protocol:\nChatbots must not engage with users unless the provider has an implemented protocol for recognizing and responding to suicidal thoughts or self-harm (including referrals to hotlines/text lines).\nThe protocol must be publicly disclosed. Mandatory reporting:\nProviders must annually report: Number of detected suicidal ideation events; Number of times a chatbot initiated discussions about suicide/self-harm; Reports must be anonymized and published online by the Office of Suicide Prevention. Third-party audits:\nPlatforms must undergo independent, regular audits for compliance with this law, and a high-level audit summary must be made publicly available for free. Minor safety disclosure: Providers must disclose on their platform (website/app) that companion chatbots may not be suitable for some minors. Private right of action:\nAnyone harmed by a violation may sue for: Injunctive relief. Minimum $1,000 per violation, or actual damages (whichever is greater) Attorney’s fees and costs",
    "SB 384": "SB 384 prohibits the use or distribution of certain AI-enabled price-setting algorithms designed to coordinate prices or rental levels between competitors using confidential, nonpublic data. The bill targets algorithmic collusion—a rising concern in antitrust enforcement—and applies civil penalties for violators. Key features: Bans sale or use of certain AI pricing tools if intended for use by 2 or more competitors in the same market and known to process nonpublic input data; Covers both digital goods/services and rental housing; Establishes civil penalties and private enforcement via the state or local attorneys; Provides a due diligence defense to companies that verify the algorithm is compliant.",
    "SB 53": "SB 53 creates a sweeping new framework for transparency and accountability in the development of high-risk AI foundation models. It imposes mandatory safety, transparency, and reporting requirements on “large developers” — i.e., entities training or fine-tuning models using ≥10²⁶ floating point operations. Key provisions: Requires large AI developers to publish and maintain a safety & security protocol, including testing, risk mitigation, and third-party audits; Mandates transparency reports and disclosures of catastrophic risk before and during deployment of foundation models; Establishes whistleblower protections for employees who report risks of AI models causing large-scale harm; Directs the creation of CalCompute, a public cloud compute platform to democratize access to AI infrastructure; Enables public and employee incident reporting to the CA Attorney General; Authorizes the Attorney General to adopt regulations to redefine “large developer” based on evolving technology."
  },
  {
    "Bill": "Link",
    "AB 2013": "https://www.bakerdonelson.com/californias-new-generative-ai-law-what-your-organization-needs-to-know",
    "SB 813": "https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB813",
    "SB 579": "https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB579&search_keywords=artificial+intelligence",
    "SB 524": "https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB524&search_keywords=artificial+intelligence",
    "SB 503": "https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB503&search_keywords=artificial+intelligence",
    "SB 853": "https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260AB853&search_keywords=artifical+intelligence",
    "SB 420": "https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB420&search_keywords=artifical+intelligence",
    "SB 833": "",
    "SB 489": "https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260AB489&search_keywords=artificial+intelligence",
    "SB 11": "https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB11&search_keywords=artificial+intelligence",
    "SB 468": "https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB468&search_keywords=artificial+intelligence",
    "AB 979": "https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260AB979&search_keywords=artifical+intelligence",
    "SB 243": "https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB243&search_keywords=artifical+intelligence",
    "SB 384": "https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB384&search_keywords=artifical+intelligence",
    "SB 53": "https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB53&search_keywords=artifical+intelligence"
  },
  {
    "Bill": "Can apply to",
    "AB 2013": "Any company offering generative AI tools to the public in California, from giants like OpenAI and Google to smaller AI developers. Exemptions include AI tools solely focused on data security or national defense.",
    "SB 813": "Developers of AI models or applications used, deployed, or distributed in California. Private entities seeking to become MROs.",
    "SB 579": "California Government Operations Agency, state and local mental health programs and professionals, stakeholders in AI/health technology providing input to the group",
    "SB 524": "All California law enforcement agencies, state and local, and peace officers (as defined under Penal Code §830) using or reviewing AI-generated police reports",
    "SB 503": "Health care providers, including clinics, hospitals, physician group practices, and solo offices, Developers and vendors who create or modify AI tools for medical decision-making, and Deployers (any user of AI in a healthcare setting)",
    "SB 853": "GenAI developers with >1M monthly users, Large online platforms (2M+ monthly users), Capture device manufacturers (smartphones, cameras, etc.), GenAI hosting platforms, Distributors of software/services designed to remove disclosure metadata",
    "SB 420": "Developers: anyone who creates or substantially modifies a high-risk automated decision system. Deployers: any person or organization using a high-risk ADS in California. State agencies: required to request assessments from vendors and ensure vendors are compliant",
    "SB 833": "State agencies operating or deploying AI systems in critical infrastructure sectors, Entities impacting critical infrastructure operations, safety, or security",
    "SB 489": "Developers and deployers of AI or GenAI systems providing health-related communication, advice, or reports, Advertising or functionality of AI systems suggesting licensed health care professional involvement",
    "SB 11": "AI tool developers and distributors, Companies offering generative AI services involving faces, voices, or likenesses, Courts handling digital evidence, Users creating deepfakes or impersonation content",
    "SB 468": "Any business deploying high-risk AI systems that process personal information of California residents",
    "AB 979": "Can apply to: Vendors, contractors, or service providers using or integrating AI with California government agencies; AI developers in the broader ecosystem who want to participate in voluntary threat info-sharing; State agencies responsible for cybersecurity oversight or procurement of AI systems",
    "SB 243": "Any company or developer offering a chatbot that simulates friendship, romance, or social companionship; Operators of platforms where these chatbots can be accessed by California users; Applies regardless of whether the service is web, app, VR, or metaverse-based",
    "SB 384": "Software vendors, AI developers, or consultants selling/licensing pricing tools; E-commerce platforms, rental property managers, landlords, or marketplaces using shared pricing software; Any entity operating in California or doing business with California-based sellers",
    "SB 53": "AI companies developing general-purpose models (GPT-class systems); Research labs deploying or training large-scale AI models; Cloud providers offering foundation model fine-tuning platforms; Any organization training models using 10²⁶ FLOPs or more (costing $100M+ at market rate)."
  },
  {
    "Bill": "Potentially affected Industries",
    "AB 2013": "AI industry broadly, especially developers of generative AI tools (text, images, audio, video). Impact on tech companies, startups, and possibly content creators who use or build AI. Also affects content owners (like artists and writers) by giving them better tools to check if their copyrighted work was used without permission.",
    "SB 813": "Artificial Intelligence & Machine Learning, Software Development, Cybersecurity, Biotech / High-risk Tech, Legal / Compliance services, Any business deploying AI in physical or digital environments",
    "SB 579": "Mental Health Services, Artificial Intelligence and Digital Health, Health Tech Startups and Vendors, Academic & Research Institutions, Public Health and State Agencies",
    "SB 524": "Law Enforcement, AI & Police Tech Vendors (e.g., body cam software, report generation tools), Legal Tech / Compliance Software, Government IT systems",
    "SB 503": "Health care delivery systems, Health tech and AI development firms, Medical software vendors, State and local government agencies operating health programs",
    "SB 853": "Big Tech & Social Media (e.g., Meta, TikTok, X), Hardware Manufacturers (Apple, Samsung, Canon, etc.), AI Developers (OpenAI, Google, Adobe, etc.), Cybersecurity & Watermarking vendors, Content-sharing platforms, advertising networks, and browsers",
    "SB 420": "Tech companies and startups building AI/ML models, Employers using AI in hiring or performance reviews, Schools and universities using AI for admissions or aid, Hospitals and insurers deploying AI for health care decisions, Banks, lenders, utilities, and landlords using automated approvals, Government agencies contracting with vendors who deploy ADS",
    "SB 833": "Transportation, Energy, Food and Agriculture, Communications, Emergency Services, Financial Services, Government agencies involved in critical infrastructure management",
    "SB 489": "Health care AI technology developers, Telehealth and digital health service providers, Medical and dental care providers using AI for patient communication or diagnostics, Health care regulatory bodies",
    "SB 11": "Generative AI platforms (e.g., text-to-video, voice cloning, avatar creation), Advertising and influencer marketing firms using AI likenesses, Media companies producing AI-generated content, Entertainment and gaming industries, Tech platforms offering user-driven AI generation (social, apps, SaaS)",
    "SB 468": "AI and machine learning developers, Adtech and data brokers, Health tech, finance tech, and HR platforms using AI for decision-making, E-commerce platforms processing personal data with AI, Cloud and SaaS providers integrating AI into enterprise services",
    "AB 979": "AI/ML platform developers; Cybersecurity companies and managed service providers; GovTech and EdTech vendors; State IT departments and agencies deploying AI-powered systems; Cloud infrastructure providers with AI capabilities serving government clients",
    "SB 243": "AI companionship/chatbot startups (e.g., Replika, Character.ai, Nomi AI); Mental health/wellness tech firms offering chatbot therapists or journaling bots; Social AI platforms that simulate long-term engagement or personas; Voice assistant developers with \"emotionally aware\" models; Gaming or metaverse firms integrating emotionally resonant NPCs/chatbots",
    "SB 384": "Rental housing management systems (especially ones using dynamic pricing, e.g., RealPage); Hospitality & travel platforms (hotels, Airbnb, OTAs with pricing optimization); Retail & e-commerce platforms using algorithmic pricing engines; AI SaaS firms offering shared pricing optimization across clients; Marketplaces and delivery platforms (e.g., rideshare/delivery services using surge or demand-based pricing); Multi-vendor inventory/pricing management systems",
    "SB 53": "Artificial Intelligence & Machine Learning; Cloud Computing & Hosting (AWS, Azure, GCP, etc.); Cybersecurity; Enterprise Software & SaaS; Biotechnology; Defense & Aerospace (if using AI R&D); Any firm training general-purpose foundation models"
  },
  {
    "Bill": "Recommended steps",
    "AB 2013": "AI developers creating generative AI models must disclose detailed info about their training data. This includes the sources, types, collection dates, and any biases or presence of copyrighted or sensitive material. The goal is to increase transparency about what data shapes AI models, tackling the notorious “black box” issue where AI decisions are mysterious. Companies must provide documentation covering all training data going back to at least 2022.",
    "SB 813": "(For developers) Optional: Seek certification from an MRO. If seeking certification: Disclose risks, incident reports, and compliance practices. Cooperate with audits, red-teaming, and risk mitigation standards. Maintain documentation and comply with any prescribed remediation. (For MROs) Apply for designation by the AG, including a detailed risk-mitigation plan. Maintain independence from AI industry. Certify/de-certify developers. Submit annual public reports. Enforce whistleblower protections. Retain documents for 10 years.",
    "SB 579": "For the Secretary of Government Operations: Appoint a 17-member working group by July 1, 2026, Ensure diverse representation (mental health experts, technologists, ethicists, patient advocates, lawmakers), Host at least 3 public meetings to gather input, Submit a report to the Legislature (by July 2028), Submit a follow-up report (by January 2030) on implementation and training frameworks",
    "SB 524": "Law enforcement agencies must: Develop and adopt a policy for handling AI-generated police reports, Include mandated disclosure and signature protocols, Ensure the AI program used keeps a detailed audit trail, Retain first drafts of AI reports alongside the final report, Treat only the final human-reviewed report as official",
    "SB 503": "Developers and deployers should: Identify high-risk AI tools with potential bias, Mitigate risks of biased outputs, Monitor AI systems regularly and respond to any harmful impacts, Track protected characteristics potentially affected by AI decision-making (as defined in Civil Code §51)",
    "SB 853": "Covered providers / developers must: Provide free AI detection tools for public use, Embed “latent disclosures” in content (hard-to-remove watermarks). Large online platforms must: Label AI-generated content, Retain system provenance data, Display conspicuous notices to users, Allow inspection of provenance info. Capture device manufacturers must: Include provenance settings in default apps, Inform users about provenance features on first use, Embed hardware-level watermarking by default, Enable third-party app access to secure provenance functions. GenAI hosting platforms must: Only host GenAI that includes strong content disclosures, Not allow AI with easily erasable markers. Distributors must not: Sell software that removes these embedded disclosures",
    "SB 420": "Developers and deployers should: Conduct and maintain an impact assessment, Share key elements of the assessment with partners and regulators, Publish online transparency statements, Disclose use of ADS to individuals affected, Provide a human appeals mechanism, Establish a governance program for bias and discrimination risk, Update assessments when substantial modifications are made, Certify compliance before winning a state contract",
    "SB 833": "State agencies must implement human oversight mechanisms on AI systems with real-time monitoring and pre-execution approval processes, Arrange or participate in AI safety and risk management training provided by Department of Technology, Conduct and document annual AI system assessments focused on compliance, performance, and risk identification, Develop internal protocols for prompt detection and reporting of AI adverse events per prescribed timelines, Establish designated reporting contacts and systems to comply with reporting requirements. Ensure data protection measures to handle sensitive AI adverse event information securely",
    "SB 489": "Audit AI and GenAI systems’ advertising and communication to ensure no unauthorized use of licensed health care professional terms or implications, Develop disclaimers or clarifications where AI systems provide health advice or reports to avoid misleading users, Train marketing and product teams on compliance with health profession licensure laws as applied to AI, Establish review and compliance checks for AI outputs that relate to health care professions, Coordinate with health care licensing boards to understand enforcement scope and reporting requirements",
    "SB 11": "If you're an AI provider, it is recommended to implement the required consumer warning system by the deadline, Audit product functionality: if your tools can create voice, image, or likeness replicas, they are subject to this law, Monitor the Department of Consumer Affairs website by July 1, 2026, for the required warning text. Revise Terms of Service and UI to clearly display this warning pre-use and link it on any input/prompt pages, If you use digital replicas in ads or commercial material, ensure proper consent is obtained, If you're a litigator or court actor, stay alert for Judicial Council rules by 2027 on AI-evidence screening",
    "SB 468": "Identify whether your AI systems qualify as “high-risk” under CA law, Perform a gap analysis against SB 468’s information security program requirements, Establish or upgrade data governance and security protocols tailored to AI processing, Designate responsible security personnel and implement continuous training for employees and contractors, Develop and test incident response plans, including post-breach audits and improvements, Audit third-party service providers for security compliance and update contracts accordingly, Prepare for potential regulatory inspections or enforcement under the Unfair Competition Law",
    "AB 979": "If you're a state contractor using AI: Be prepared to report threats or vulnerabilities you discover to Cal-CSIC once the Playbook is released; Review upcoming requirements in federal CISA/JCDC standards to align with both federal and California cybersecurity expectations. Review internal security protocols to ensure: You're not exposing the state to known but unreported AI-related vulnerabilities; Personnel handling government AI deployments are authorized and trained on secure use. For voluntary participants in AI threat sharing: Consider opting in to gain access to emerging threat intelligence. If you manage sensitive public-sector data: Be aware that disclosure of cyber-threat data will be legally restricted — plan for internal compliance and communication guidelines.",
    "SB 243": "Audit reward systems: Eliminate reinforcement learning loops or gamified behaviors tied to random or intermittent reward structures. AI labeling: Implement a persistent or timed banner/modal that discloses the artificial nature of the chatbot as required. Mental health protocol: Deploy keyword flagging models to detect suicidal ideation or self-harm language; Develop a referral system that links to 988 Suicide & Crisis Lifeline, text lines, or emergency support; Publish your response policy clearly on your website. Prepare for audits: Contract with an independent third-party auditor with AI/mental health tech experience; Design internal tracking systems for required user interaction metrics; Update TOS/UX copy: Add disclosures for minors and for public-facing audit summaries; Litigation preparedness: Update your legal risk profile and ensure compliance to avoid user lawsuits under this bill.",
    "SB 384": "Audit algorithm use cases: Ensure algorithms do not use data from multiple competitors to jointly influence price or supply. Due diligence documentation: For developers: Provide written statements certifying compliance (non-use of nonpublic competitor data). For users: Retain documentation of due diligence inquiries made to vendors. Isolate sensitive data: Segregate internal pricing data from multi-tenant/shared algorithmic engines. Review vertical integration practices: Ensure parent-subsidiary data sharing doesn’t unintentionally cross into horizontal competitor coordination. Contract updates: Revise licensing terms to explicitly prohibit use with competitor data; Require compliance certifications in client/vendor relationships.",
    "SB 53": "Audit compute usage to determine if your foundation models meet the FLOPs threshold. Draft a comprehensive safety and security protocol, including: Risk testing; Incident response plans; Security around unreleased model weights; Establish or review internal anonymous whistleblower mechanisms; Begin transparency reporting on catastrophic risks and testing results; Identify contracts, policies, or NDAs that could violate new whistleblower protections; Prepare to comply with CalCompute participation if seeking state-funded compute infrastructure."
  },
  {
    "Bill": "Potential Penalties",
    "AB 2013": "Specific penalties aren’t detailed in your info, but given it’s a transparency law, noncompliance likely risks regulatory enforcement actions and potential fines. The risk level is probably moderate to immediate because compliance is mandatory starting in 2026 for existing and new models.",
    "SB 813": "For MROs: Revocation of designation if they fail to follow their approved plan or if certified models cause harm. For Developers: Loss of certification if noncompliant. No shield from liability without MRO certification. No criminal penalties are specified—this bill operates primarily through incentives and civil litigation frameworks.",
    "SB 579": "None specified. This bill does not impose penalties—it is a fact-finding, research, and recommendation mandate, not a regulatory or enforcement statute.",
    "SB 524": "No specific criminal or civil penalties are outlined, but failure to comply would: Violate state law, Expose departments to litigation or civil rights challenges, Potentially trigger state audits or mandates, Additionally, state reimbursement is required if implementation imposes new local costs.",
    "SB 503": "No specific fines or penalties listed in the bill itself, but: Compliance does not protect against legal claims under existing civil rights or anti-discrimination law. Failure to identify or mitigate bias could result in legal liability under the Unruh Civil Rights Act or ADA",
    "SB 853": "$5,000 per violation per day, Attorney’s fees and legal costs to the plaintiff, Additional injunctive relief available for some third-party licensee violations, Civil enforcement by Attorney General, city attorneys, or county counsel",
    "SB 420": "Enforced by the Attorney General or Civil Rights Department: Failure to do impact assessment: $2,500 (under 100 employees), $5,000 (under 500 employees), $10,000 (500+ employees), Add $500/day for intentional noncompliance. Algorithmic discrimination: $25,000 per violation. Injunctive relief and attorney’s fees. 45-day cure period before enforcement, with perjury-backed certification",
    "SB 833": "Civil penalty up to $500 per each 7-day period for failure to timely submit required AI adverse event reports",
    "SB 489": "Enforcement actions by health care professional licensing boards, Injunctions or restraining orders against unlawful AI use of protected health care professional terms, Each unauthorized use of protected terms may be treated as a separate violation, multiplying potential penalties",
    "SB 11": "Civil penalty of up to $25,000 per day per non-compliant offering of digital replica tools; Civil liability under California’s right-of-publicity laws (§3344) for unauthorized AI likeness use; Criminal liability under Penal Code §528.5, §529, §530 when a digital replica is used for impersonation",
    "SB 468": "Violations qualify as deceptive trade practices, triggering penalties under California’s Unfair Competition Law May include injunctions, civil penalties, reputational damage, and potential class action exposure",
    "AB 979": "While this bill does not explicitly create penalties, non-compliance with mandatory sharing mechanisms for state contractors could lead to: Contract breach, termination, or non-renewal; Increased scrutiny under existing state cybersecurity audits; Regulatory or administrative penalties under procurement compliance laws",
    "SB 243": "Civil lawsuits by harmed users; Minimum $1,000 per violation; Additional damages + attorney’s fees; Reputational damage from failed audits or noncompliance reports published by the Office of Suicide Prevention; Increased regulatory scrutiny, especially if your chatbot triggers or mishandles suicidal ideation",
    "SB 384": "$1,000 per violation; Each license/user of a noncompliant algorithm = separate violation; Each calendar month of use = separate violation for users; Attorney General, district attorney, city attorney, or county counsel can bring civil actions; Injunctive relief, restitution, and actual damages may be pursued; Mandatory attorney's fees awarded to prevailing state/local prosecutors",
    "SB 53": "Civil penalties (amount TBD in final bill) for violations; Higher penalties if violations are found to be willful or reckless; Injunctive relief and attorney’s fees for whistleblowers who prevail in lawsuits."
  },
  {
    "Bill": "Potential Risk",
    "AB 2013": "Moderate to Immediate, because companies must trace back years of training data and meet strict documentation standards.",
    "SB 813": "Legal liability for developers without certification in personal injury/property damage claims. Reputational risk for non-certified models in a regulated environment. MROs risk revocation and public scrutiny if oversight fails or conflicts of interest are discovered.",
    "SB 579": "Low regulatory risk, as this is an exploratory bill. However, findings from the reports may lead to future regulations on AI in mental health.",
    "SB 524": "Moderate compliance and reputational risk for law enforcement: Risk of lawsuits or mistrials if improperly handled reports are used, Public distrust if AI use isn’t transparent, and Technical risk if audit trails or data retention fail",
    "SB 503": "High compliance and legal risk if bias is left unchecked, Public trust concerns if biased systems harm patient care, Possible civil rights litigation exposure, Operational risk from not updating or auditing AI regularly",
    "SB 853": "Major financial exposure for large platforms and device makers, Brand damage if disclosure tools are absent or easy to strip, Possible lawsuits from AG or civil society groups, Compliance complexity for international AI and device firms",
    "SB 420": "High legal and operational risk if deploying unassessed or biased AI, State agencies barred from contracting with violators, Noncompliance opens door to civil lawsuits and reputation damage, Trade secret disputes may arise when refusing to disclose algorithmic logic, Exemptions apply to small orgs (≤50 employees) and federally approved systems",
    "SB 833": "Operational disruptions or safety failures due to inadequate AI oversight, Financial penalties from noncompliance with reporting requirements, Loss of public trust or increased scrutiny if adverse events are not properly managed and disclosed internally, Risk of destabilizing critical infrastructure if oversight mechanisms interfere with urgent automated decision systems",
    "SB 489": "Legal and regulatory sanctions for AI developers and deployers, Damage to reputation and trust if AI systems mislead users about licensed health care professional involvement, Increased scrutiny from health boards leading to stricter oversight or fines",
    "SB 11": "Public backlash or consumer lawsuits from misuse of AI likeness tools; Lawsuits for unconsented likeness use, especially for public figures or commercial exploitation; Enforcement actions from public prosecutors under the Unfair Competition Law; Admissibility challenges in courts related to AI-generated evidence",
    "SB 468": "Legal and financial liability for failing to safeguard consumer data in AI deployments Regulatory scrutiny from the California Privacy Protection Agency Risk of consumer lawsuits under private right of action provisions in data privacy law Technical debt or operational disruption from retroactive compliance requirements if passed",
    "AB 979": "Mismanagement of sensitive AI threat info could lead to data leaks or regulatory risk if information is mishandled; Public backlash if a vendor fails to report a known vulnerability that leads to a breach; Being barred from future public contracts for failure to participate in the mandated threat-reporting structure",
    "SB 243": "Platforms using RLHF (reinforcement learning from human feedback) may risk reinforcing compulsive use patterns; Failure to detect or address suicidal ideation could expose providers to liability or regulatory blowback, especially in high-profile harm cases; Minors using emotionally manipulative chatbots without proper warnings may spark media or legislative backlash.",
    "SB 384": "Companies using shared pricing tools (especially in rental markets) risk triggering state antitrust-style enforcement; Violations could become repeat offenses monthly, adding up fast; Algorithms powered by RLHF (reinforcement learning) or cross-client learning architectures are at elevated risk; Potential investigations into algorithm vendors by the California AG could also lead to broader scrutiny",
    "SB 53": "High — Noncompliance may result in litigation, fines, reputational damage, and loss of market access in California. Particularly risky for developers of powerful AI models that could be seen as posing catastrophic risks (e.g. autonomous weapons, AI-driven cyberattacks)."
  },
  {
    "Bill": "Tags",
    "AB 2013": "AIRegulation · Transparency · GenerativeAI · TrainingDataDisclosure · EthicalAI · BiasMitigation · Copyright · CaliforniaLaw · TechCompliance",
    "SB 813": "AI Safety · AI Governance · Certification · Risk Mitigation · Civil Liability · Cybersecurity · Transparency · AI Compliance · Legal Defense · California",
    "SB 579": "AI in Healthcare · Mental Health · California AI Policy · Working Group · Digital Therapy · AI Risk Analysis · Public Sector AI · Ethics & Law · Training Framework",
    "SB 524": "AI in Law Enforcement · Transparency · Police Reports · Audit Trails · Body Cam AI · Generative AI · California Public Safety · Artificial Intelligence Regulation",
    "SB 503": "AI in Healthcare · Algorithmic Bias · Protected Characteristics · Clinical Decision-Making · Health Equity · Patient Rights · AI Regulatio",
    "SB 853": "AI Transparency · Provenance Watermarking · Digital Authenticity · AI Regulation · Content Verification · Consumer Protection · Latent Disclosures",
    "SB 420": "AI Governance · High-Risk AI · Algorithmic Discrimination · Impact Assessment · ADS Regulation · Bias Audits · Transparency · Human Review",
    "SB 833": "AIRegulation · CriticalInfrastructure · HumanOversight · RiskManagement · AdverseEventReporting · PublicSafety · CaliforniaLaw · TechCompliance · DataSecurity",
    "SB 489": "AIRegulation · HealthCare · LicensingCompliance · GenerativeAI · ConsumerProtection · CaliforniaLaw · TechCompliance · DigitalHealth",
    "SB 11": "Deepfakes · DigitalReplicas · RightOfPublicity · ConsumerProtection · AIRegulation · EvidenceLaw · CaliforniaLaw · FalseImpersonation · TechCompliance · EntertainmentLaw",
    "SB 468": "AIRegulation · HighRiskAI · DataPrivacy · InformationSecurity · CPRA · ConsumerProtection · UnfairCompetition · CaliforniaLaw · TechCompliance · Cybersecurity",
    "AB 979": "AIThreats · Cybersecurity · PublicRecordsExemption · GovernmentAI · InfrastructureSecurity · TechVendors · CaliforniaLaw · JCDC · InformationSharing · AICompliance",
    "SB 243": "CompanionAI · MentalHealth · AIRegulation · Chatbots · SuicidePrevention · ChildrenSafety · TechAccountability · CaliforniaLaw · AddictiveDesign · EthicalAI",
    "SB 384": "AlgorithmicPricing · Antitrust · AIRegulation · Collusion · RentalMarket · DynamicPricing · CaliforniaLaw · TechAccountability · CompetitionLaw · PriceFixing",
    "SB 53": "AIRegulation · Transparency · FoundationModels · SafetyProtocol · WhistleblowerProtection · CatastrophicRisk · CalCompute · CaliforniaLaw · TechCompliance · GenerativeAI"
  },
  {
    "Bill": "Who should comply",
    "AB 2013": "Any company or developer offering generative AI tools to the public in California. Covers models trained since 2022 – even older models must be documented. AI systems used exclusively for: national defense and cybersecurity are exempt.",
    "SB 813": "Developers of AI systems used in California if seeking liability protection. MROs designated under this bill must comply with strict audit, independence, and reporting standards.",
    "SB 579": "California Secretary of Government Operations, Appointed working group members, Participating stakeholders (e.g., health orgs, universities, AI companies) providing input, Compliance is procedural, not regulatory",
    "SB 524": "All California law enforcement agencies using or planning to use AI in: Report drafting, Video/audio analysis, Narrative generation from body/dash cam or officer dictation",
    "SB 503": "All California-based: Hospitals, Health clinics, Physician group practices, Solo providers, Government health departments, AI developers serving the health sector, Vendors offering decision support or resource allocation tools",
    "SB 853": "GenAI developers with large user bases, Social media and content-distribution platforms, Smartphone and camera manufacturers, GenAI service providers and distributors, Software vendors with AI detection or watermark removal tools",
    "SB 420": "Tech developers (AI, ML, data science, automation), Public/private deployers using AI in critical decisions, Vendors hoping to contract with California agencies, Government departments using AI in housing, education, hiring, or health",
    "SB 833": "State agencies identified as operators of critical infrastructure AI systems, Other entities materially impacting critical infrastructure safety, security, or operations",
    "SB 489": "AI/GenAI developers and deployers operating within or targeting California health care markets, Health care organizations integrating AI tools for patient-facing communications or decision support",
    "SB 11": "Any business that sells or offers AI tools capable of generating digital replicas; Developers and publishers of voice cloning, video manipulation, or avatar tech; Marketers, ad firms, and content producers using AI-generated likenesses; Legal practitioners and courts processing AI-generated evidence",
    "SB 468": "Businesses of any size that deploy high-risk AI systems which process personal information of California consumers",
    "AB 979": "Any AI vendor or contractor working with California state agencies; Public institutions using third-party AI services; State cybersecurity bodies managing threat response or procurement; Voluntary private-sector partners who adopt the playbook framework",
    "SB 243": "Any operator of a chatbot platform with long-form, emotionally interactive, human-like AI; Developers of AI companionship tools targeting or available to California users; Mental health and wellness tech companies with automated conversational agents; Platforms facilitating access to emotionally aware bots, regardless of their primary market",
    "SB 384": "Developers of price-setting algorithms intended for multiple commercial clients; Landlords or rental platforms using third-party tools for pricing; E-commerce sellers and platforms coordinating pricing strategies using shared or off-the-shelf AI tools; AI consultants and SaaS firms building custom pricing engines",
    "SB 53": "All companies or individuals developing foundation models using >10²⁶ FLOPs; AI teams deploying such models to the public or to third parties; Contractors, advisors, and workforce entities interacting with high-risk AI development."
  },
  {
    "Bill": "Source",
    "AB 2013": "Baker Donelson",
    "SB 813": "California Legislative Information & LEGISCAN",
    "SB 579": "California Legsilative Information & LEGISCAN",
    "SB 524": "California Legsilative Information & LEGISCAN",
    "SB 503": "California Legsilative Information & LEGISCAN",
    "SB 853": "California Legsilative Information & LEGISCAN",
    "SB 420": "California Legsilative Information & LEGISCAN",
    "SB 833": "California Legsilative Information & LEGISCAN",
    "SB 489": "California Legsilative Information & LEGISCAN",
    "SB 11": "California Legsilative Information & LEGISCAN",
    "SB 468": "California Legsilative Information & LEGISCAN",
    "AB 979": "California Legsilative Information & LEGISCAN",
    "SB 243": "California Legsilative Information & LEGISCAN",
    "SB 384": "California Legsilative Information & LEGISCAN",
    "SB 53": "California Legsilative Information & LEGISCAN"
  },
  {
    "Bill": "Citation",
    "AB 2013": "California Assembly Bill No. 2013 (2025–2026 Session), “An Act to Require Disclosure of Training Data for Generative AI Models,” effective January 1, 2026.",
    "SB 813": "SB 813 (McNerney), 2025–2026 Regular Session, California State Legislature. Adds Chapter 14 (commencing with Section 8898) to Division 1 of Title 2 of the Government Code.",
    "SB 579": "SB 579 (Padilla), 2025–2026 Regular Session, adds Section 12817 to the California Government Code.",
    "SB 524": "SB 524 (Arreguín), 2025–2026 Regular Session, adds Section 13663 to the California Penal Code.",
    "SB 503": "SB 503 (Weber Pierson), 2025–2026 Regular Session, adds Section 1339.76 to the Health and Safety Code.",
    "SB 853": "AB 853 (Wicks), 2025–2026 Regular Session, amends and adds to Section 22757 of the Business and Professions Code.",
    "SB 420": "SB 420 (Padilla), 2025–2026 Regular Session, adds Chapter 24.6 to Division 8 of the Business and Professions Code and Article 11 (starting at Section 10285.8) to the Public Contract Code",
    "SB 833": "California Senate Bill No. 833 (2025–2026 Session), “An Act to Add Sections 8592.51 and 8592.52 to the Government Code Relating to State Government Critical Infrastructure and AI Oversight,” pending enactment.",
    "SB 489": "California Assembly Bill No. 489 (2025–2026 Session), “An Act to Add Chapter 15.5 to the Business and Professions Code Relating to Deceptive Terms or Letters in Artificial Intelligence Health Communications,” pending enactment.",
    "SB 11": "California Senate Bill No. 11 (2025–2026 Session), “An Act Relating to Artificial Intelligence Technology,” effective January 1, 2026 (pending enactment).",
    "SB 468": "California Senate Bill No. 468 (2025–2026 Session), “An Act to Add Title 1.81.28 to the Civil Code Relating to High-Risk Artificial Intelligence Systems and Personal Information Security,” pending enactment.",
    "AB 979": "California Assembly Bill No. 979 (2025–2026 Session), “An Act to Enhance Cybersecurity Coordination for AI Systems,” effective upon enactment, with implementation due by July 1, 2026.",
    "SB 243": "California Senate Bill No. 243 (2025–2026 Session), “An Act to Regulate Companion Chatbot Safety and Mental Health Protocols,” effective January 1, 2026.",
    "SB 384": "California Senate Bill No. 384 (2025–2026 Session), “The Preventing Algorithmic Price Fixing Act,” effective January 1, 2026.",
    "SB 53": "Senate Bill No. 53 (2025–2026 Session), “Transparency in Frontier Artificial Intelligence Act,” introduced by Senator Wiener and Senator Rubio, effective January 1, 2026 (pending enactment)."
  },
  {
    "Bill": "Potentially enforced by",
    "AB 2013": "California",
    "SB 813": "California Attorney General, who: Designates and regulates MROs, oversees fee structures and rules, receives annual reports and enforces plan compliance.",
    "SB 579": "California Government Operations Agency; no enforcement agency in the traditional sense—responsibility rests with the Secretary of Government Operations to carry out the bill's mandates.",
    "SB 524": "Local Law Enforcement Agencies (internal compliance), California Commission on State Mandates, if reimbursement is triggered, State oversight bodies or courts in case of non-compliance litigation",
    "SB 503": "California Department of Public Health (CDPH), California Department of Health Care Services (DHCS). Possibly subject to civil enforcement by patients or advocacy organizations under existing state/federal laws",
    "SB 853": "California Attorney General, County counsel, City attorneys, Civil enforcement with court-imposed penalties and injunctive powers",
    "SB 420": "California Attorney General, California Civil Rights Department (CRD), State agencies when awarding contracts",
    "SB 833": "California Office of Emergency Services, California Department of Technology, Relevant state regulatory and enforcement bodies overseeing critical infrastructure and cybersecurity compliance",
    "SB 489": "Appropriate California health care professional licensing boards (Medical Board, Dental Board, etc.), California Department of Consumer Affairs, Relevant courts via injunctions or restraining orders",
    "SB 11": "Department of Consumer Affairs (for warning requirements); Public Prosecutors (civil penalty enforcement); California courts (false impersonation or evidence admissibility); Private plaintiffs under Civil Code §3344",
    "SB 468": "California Privacy Protection Agency (CPPA), California Office of the Attorney General (via Unfair Competition Law), Courts (civil enforcement, consumer protection actions)",
    "AB 979": "California Office of Emergency Services (OES); California Cybersecurity Integration Center (Cal-CSIC); State contracting authorities, depending on agency",
    "SB 243": "Office of Suicide Prevention (CDPH); Independent third-party auditors; California courts, via private right of action",
    "SB 384": "California Attorney General; Local prosecutors (District Attorney, City Attorney, or County Counsel)",
    "SB 53": "California Attorney General (primary); Courts (civil penalties, injunctions); Whistleblowers via civil litigation"
  }
]